{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Block Gibbs Sampling Assignment 4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-XD0C0fT6LH",
        "outputId": "0a4cd9d1-195f-43c3-dcab-9b8122a9f77d"
      },
      "source": [
        "!pip install wandb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.10.30)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: sentry-sdk>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.1.0)\n",
            "Requirement already satisfied: subprocess32>=3.5.3 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.5.4)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.17)\n",
            "Requirement already satisfied: configparser>=3.8.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.0.2)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (8.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (56.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.0; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.7.4.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.7)\n",
            "Requirement already satisfied: smmap<5,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (4.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pk1JX9Z8OvrK"
      },
      "source": [
        "***Importing Libraries and Load Data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tH8IIFC4UMPg",
        "outputId": "375db65c-5d61-4725-e909-ba5943e5d5d9"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.datasets import mnist\n",
        "from sklearn.manifold import TSNE\n",
        "import wandb\n",
        "\n",
        "# load dataset\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "class_type = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat','Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'] \n",
        "\n",
        "proj_name='CS6910 ASSIGNMENT 4 GIBBS'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JBDFxo1OjPA"
      },
      "source": [
        "***Modify and Restructure Data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWyanHGZYK_5"
      },
      "source": [
        "# Initializations\n",
        "\n",
        "# Data\n",
        "X_train = np.array(x_train.reshape(x_train.shape[0], 784,1))         # reshape 2-D data to 1-D\n",
        "X_test  = np.array(x_test.reshape(x_test.shape[0], 784,1))           # reshape 2-D data to 1-D\n",
        "X_train = (X_train > 126) * 1                                        # convert the real valued data into binary data, using a threshold of 127\n",
        "X_test  = (X_test > 126) * 1                                         # convert the real valued data into binary data, using a threshold of 127\n",
        "\n",
        "X_val = X_train[-15000:]                                             # validation set input (to train Classifier)\n",
        "X_train = X_train[0:45000]                                           # training set input (to train RBM)\n",
        "\n",
        "Y_train = np.zeros([len(y_train),10,1])\n",
        "Y_test = np.zeros([len(y_test),10,1])\n",
        "\n",
        "for i in range(len(y_train)):                                        # convert y from just a class number to one hot vector (10x1)\n",
        "  y = np.zeros([10, 1])\n",
        "  y[y_train[i]] = 1.0\n",
        "  Y_train[i] = y\n",
        "\n",
        "for i in range(len(y_test)):                                         # convert y from just a class number to one hot vector (10x1)\n",
        "  y = np.zeros([10, 1])\n",
        "  y[y_test[i]] = 1.0\n",
        "  Y_test[i] = y                                                      # test set output\n",
        "\n",
        "Y_val = Y_train[-15000:]                                             # validation set output\n",
        "Y_train = Y_train[0:45000]                                           # training set output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMIBhHkmOcLU"
      },
      "source": [
        "***Hyperparameters and Basic variables***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gA9IZFltcaJq"
      },
      "source": [
        "n_visible = X_train.shape[1]                                         # number of visible neurons\n",
        "n_train_examples = X_train.shape[0]                                  # number of training data\n",
        "n_val_examples = X_val.shape[0]                                      # number of validation data\n",
        "n_test_examples = X_test.shape[0]                                    # number of test data\n",
        "n_hidden = 80                                                        # number of hidden neurons\n",
        "n_class = 10\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5jcNzIFzF4-"
      },
      "source": [
        "***Parameter Initialization (Weights and Biases)***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6hjDjNRc1FR"
      },
      "source": [
        "def rbm_param_init() :                                                                        # Function to randomly initialize the RBM network parameters \n",
        "\t\n",
        "  rbm_parameters = {}\n",
        "  rbm_parameters[\"W\"] = np.random.randn(n_hidden, n_visible)*np.sqrt(6./(n_visible + n_hidden))   # Xavier Initialization of weights\n",
        "  rbm_parameters[\"h_bias\"] = np.zeros((n_hidden,1),dtype=np.float64)                                                     \n",
        "  rbm_parameters[\"v_bias\"] = np.zeros((n_visible,1),dtype=np.float64)\n",
        "\n",
        "  return rbm_parameters\n",
        "\n",
        "def classifier_param_init() :                                                                 # Function to randomly initialize the Classifier network parameters\n",
        "\n",
        "  classifier = {}\n",
        "  classifier[\"W\"] = np.random.randn(n_class, n_hidden)*np.sqrt(6./(n_class + n_hidden))       # Xavier Initialization of weights\n",
        "  classifier[\"b\"] = np.zeros((n_class,1),dtype=np.float64)\n",
        "\n",
        "  return classifier\n",
        "\n",
        "def sigmoid(x) :                                                                              # RBM hidden layer activation function \n",
        "\t\n",
        "  return 1.0/(1.0+np.exp(-x))\n",
        "\n",
        "def softmax(x):                                                                               # Output activation function\n",
        "    \n",
        "  return np.exp(x) / np.sum(np.exp(x))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSGgVr3ZO8-a"
      },
      "source": [
        "***RBM and Classifier Trainer***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKRIg5kXoNlj"
      },
      "source": [
        "def rbm_train(X_train,parameters,k,r,learning_rate) :\n",
        "  \n",
        "  W = parameters[\"W\"]\n",
        "  h_bias = parameters[\"h_bias\"]\n",
        "  v_bias = parameters[\"v_bias\"]\n",
        "\n",
        "  for i in range(n_train_examples) :\n",
        "    \n",
        "      v_init = X_train[i]\n",
        "      v_sample = np.random.randint(2, size=np.shape(X_train[i]))\n",
        "      dw       = np.zeros(np.shape(W))\n",
        "      dv       = np.zeros(np.shape(v_bias))\n",
        "      dh       = np.zeros(np.shape(h_bias))\n",
        "                          \n",
        "      for t in range(k + r):\n",
        "         if t < k:\n",
        "                                                                                            # Markov Chain - Loop\n",
        "            h_given_v = sigmoid(np.dot(W,v_sample)+h_bias)                                  # Evaluate p(h|v)\n",
        "            h_sample = np.random.binomial(1,h_given_v)                                      # Convert to 0's and 1's assuming binomial distribution p(h|v) \n",
        "            v_given_h = sigmoid(np.dot(np.transpose(W),h_sample)+v_bias)                    # Evaluate p(v|h)\n",
        "            v_sample = np.random.binomial(1,v_given_h)                                      # Convert to 0's and 1's assuming binomial distribution p(v|h)\n",
        "         \n",
        "         else:\n",
        "            \n",
        "            h_given_v = sigmoid(np.dot(W,v_sample)+h_bias)                                  # Evaluate p(h|v)\n",
        "            h_sample = np.random.binomial(1,h_given_v)                                      # Convert to 0's and 1's assuming binomial distribution p(h|v) \n",
        "            v_given_h = sigmoid(np.dot(np.transpose(W),h_sample)+v_bias)                    # Evaluate p(v|h)\n",
        "            v_sample = np.random.binomial(1,v_given_h)                                      # Convert to 0's and 1's assuming binomial distribution p(v|h)\n",
        "            \n",
        "            dw = dw + 1/r*(np.dot(sigmoid(np.dot(W,v_sample)+h_bias),np.transpose(v_sample)))  # Last r samples are used to form the average term in update\n",
        "            dv = dv + 1/r*(v_sample)\n",
        "            dh = dh + 1/r*(sigmoid(np.dot(W,v_sample)+h_bias))\n",
        "\n",
        "\n",
        "      # Update Rule\n",
        "      W = W + learning_rate*(np.dot(sigmoid(np.dot(W,v_init)+h_bias),np.transpose(v_init)) - dw)\n",
        "      v_bias = v_bias + learning_rate*(v_init-dv)\n",
        "      h_bias = h_bias + learning_rate*(sigmoid(np.dot(W,v_init)+h_bias) - dh)\n",
        "  \n",
        "  \n",
        "  parameters[\"W\"] = W\n",
        "  parameters[\"h_bias\"] = h_bias\n",
        "  parameters[\"v_bias\"] = v_bias\n",
        "  print(\"Training Complete\")\n",
        "\n",
        "  return parameters\n",
        "\n",
        "\n",
        "def get_hidden(x,parameters) :                                                                # function to get the hidden representation of the test data\n",
        "   \n",
        "    W = parameters[\"W\"]\n",
        "    h_bias = parameters[\"h_bias\"]\n",
        "    hidden_prob = sigmoid(np.dot(W,x)+h_bias)\n",
        "    hidden_rep = np.random.binomial(1,hidden_prob)\n",
        "    \n",
        "    return hidden_rep\n",
        "\n",
        "def classifier_train(X,Y,rbm_parameters,classifier_param,classifier_epochs,learning_rate)  :  # Function to train Classifier\n",
        "    \n",
        "    W = classifier_param[\"W\"]\n",
        "    b = classifier_param[\"b\"]\n",
        "    \n",
        "    for epoch in range(classifier_epochs) :\n",
        "      for i in range(n_val_examples) :\n",
        "         # feed forward\n",
        "         hidden_rep = get_hidden(X[i],rbm_parameters)                                         # Obtain hidden representation for the given sample\n",
        "         pre_output = np.dot(W,hidden_rep)+b\n",
        "         y_hat = softmax(pre_output)\n",
        "         # backpropogate\n",
        "         dW = np.dot(-(Y[i]-y_hat),np.transpose(hidden_rep))\n",
        "         db = -(Y[i]-y_hat)\n",
        "         # Update Classifier weights\n",
        "         W = W - learning_rate*dW\n",
        "         b = b - learning_rate*db\n",
        "\n",
        "    classifier_param[\"W\"] = W\n",
        "    classifier_param[\"b\"] = b \n",
        "    \n",
        "    return classifier_param   \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPOct2Jubjwi"
      },
      "source": [
        "def rbm_classifier(X_train,Y_train,X_val,Y_val,X_test,Y_test,rbm_epochs,classifier_epochs,k,r,n_hidden,learning_rate) :\n",
        "  classifier_param = classifier_param_init() \n",
        "  rbm_parameters = rbm_param_init()\n",
        "\n",
        "  for j in range(rbm_epochs) :\n",
        "\n",
        "     rbm_parameters = rbm_train(X_train,rbm_parameters,k,r,learning_rate)                                             # Train RBM for one epoch\n",
        "     classifier_param = classifier_train(X_val,Y_val,rbm_parameters,classifier_param,classifier_epochs,learning_rate) # Train the classifier with hidden representation of RBM\n",
        "     \n",
        "     accuracy = 0.0\n",
        "     loss = 0.0 \n",
        "     # Evaluate accuracy and loss over test data\n",
        "     for i in range(n_test_examples) :\n",
        "        h = get_hidden(X_test[i],rbm_parameters)\n",
        "        y_hat = softmax(np.dot(classifier_param[\"W\"],h)+classifier_param[\"b\"])\n",
        "\n",
        "        if y_hat.argmax()==Y_test[i].argmax():\n",
        "            accuracy = accuracy + 1\n",
        "        loss = loss + -1*np.sum(np.multiply(y,np.log(y_hat)))\n",
        "\n",
        "     accuracy = accuracy/n_test_examples\n",
        "     loss = loss/n_test_examples \n",
        "     print(\"Epoch :\" + str(j)+\" \"+ str(accuracy)+\" \"+str(loss))\n",
        "     wandb.log({\"Accuracy\":accuracy,\"Loss\":loss,\"Epoch\":j})\n",
        "  \n",
        "  return rbm_parameters,classifier_param\n",
        "      \n",
        "\n",
        "\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj2gP0OWUK8r"
      },
      "source": [
        "def train():\n",
        "  hyperparameter_defaults=dict(\n",
        "        rbm_epochs = 5,\n",
        "        classifier_epochs = 3,\n",
        "        k = 40,\n",
        "        r = 20,\n",
        "        n_hidden = 80,\n",
        "        learning_rate = 0.001                                                                    \n",
        "        )\n",
        "\n",
        "  wandb.init(config=hyperparameter_defaults)\n",
        "\n",
        "  config=wandb.config\n",
        "  rbm_parameters,classifier_param = rbm_classifier(X_train,Y_train,X_val,Y_val,X_test,Y_test,config.rbm_epochs,config.classifier_epochs,config.k,config.r,config.n_hidden,config.learning_rate)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "addT0XZjvWC0"
      },
      "source": [
        "def sweeper(sweep_config,proj_name):\n",
        "  sweep_id = wandb.sweep(sweep_config,project=proj_name,entity='cs6910krsrd',)\n",
        "  wandb.agent(sweep_id,train,project=proj_name,entity='cs6910krsrd',)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckwNuoUM2nbN"
      },
      "source": [
        "#sweep dictionary\n",
        "sweep_config={\n",
        "    'method':'bayes',\n",
        "    'metric':{\n",
        "        'name':'accuracy',\n",
        "        'goal':'maximize'},\n",
        "\n",
        "}\n",
        "\n",
        "parameters_dict={\n",
        "    \n",
        "    'rbm_epochs':{\n",
        "      'values':[5]  \n",
        "    },\n",
        "    'classifier_epochs':{\n",
        "        'values':[1]\n",
        "    },\n",
        "    'k':{\n",
        "        'values':[200]   #,500,1000]\n",
        "    },\n",
        "    'r':{\n",
        "        'values':[10]\n",
        "    },\n",
        "    'n_hidden':{\n",
        "        'values':[64]      #,128,256]\n",
        "    },\n",
        "    'learning_rate':{\n",
        "        'values':[0.01]\n",
        "    }\n",
        "    \n",
        "}\n",
        "\n",
        "sweep_config['parameters']=parameters_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgFpMnsL9xpx"
      },
      "source": [
        "sweeper(sweep_config,proj_name)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}